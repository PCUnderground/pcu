<!DOCTYPE html>
<html lang="de">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="style.css">
	<title>Licht in Echtzeit (PC Underground, PC Magazin 7/2001)</title>
</head>
<body>
	<div class="credits">
		<h2>Dieser Artikel erschien erstmals im PC&nbsp;Magazin&nbsp;7/2001. Die Wieder&shy;ver√∂ffentlichung erfolgt mit freundlicher Genehmigung der <a rel="external nofollow noreferrer" href="https://wekanet.de">WEKA&nbsp;Media&nbsp;Publishing&nbsp;GmbH</a>.</h2>
	</div>

	<nav class="pagenav">
		<a rel="prev" href="200106.html">6/2001</a>
		<a href="index.html">Inhalt</a>
		<a rel="next" href="200108.html">8/2001</a>
	</nav>

	<article>
	<header>
		<h2>Fortschrittliche Rendertechniken: Bumpmapping</h2>
		<h1>Licht in <span class="highlight">Echtzeit</span></h1>
		<p class="summary">Mit Bumpmapping <span class="highlight">verst√§rken Sie den realistischen Eindruck</span> von 3D-Grafiken. Komplexe und detailreiche Oberfl√§chen t√§uschen Wirklichkeit vor.</p>
	</header>

	<section>
		<h3>Carsten Dachsbacher</h3>
		<p>3D-Hardware-Entwickler bieten st√§ndig neue Optionen an, die die 3D-Grafik-Programmierer ausf√ºllen m√ºssen. Dazu geh√∂rt auch das von moderner Hardware unterst√ºtzte Bumpmapping in OpenGL: ein Verfahren, das den realistischen Eindruck von 3D-Objekt&shy;oberfl√§chen unterstreicht. Anders als Texture-Mapping, das auf die Farbe der Objektober&shy;fl√§chen abzielt, wird Bumpmapping dazu verwendet, Unebenheiten der Oberfl√§chen&shy;struktur zu rendern. Im Bild unten sehen Sie einen Torus als Drahtgitter&shy;modell, texturiert und mit Bumpmapping.</p>
		<figure class="floatleft">
			<img src="assets/200107_1.jpg" width="319" height="261" alt="EIN OBJEKT als Drahtgittermodell mit und ohne Bumpmapping">
			<figcaption><span>EIN OBJEKT</span> als Drahtgittermodell mit und ohne Bumpmapping</figcaption>
		</figure>
		<p>Mit Bumpmapping k√∂nnen Sie Beulen auf der Oberfl√§che von 3D-Objekten darstellen. Objekte in einer so hohen geometrischen Aufl√∂sung zu rendern, um solche Effekte zu erzielen, ist sehr rechenzeit- und speicher&shy;intensiv. Abgesehen davon, sind die Unebenheiten im Vergleich zur groben geometrischen Form eines Objekts sehr klein. Nehmen Sie als Beispiel das 3D-Modell eines Holztisches. Die Unregel&shy;m√§√üigkeiten auf der Tischfl√§che sind klein im Vergleich zur ihrer ebenen Form. Deshalb liegt es nahe, nicht die Geometriedaten selbst so fein zu gestalten.</p>
	</section>

	<aside>
		<h2>QUELLTEXTE</h2>
		<div>Die Quelltexte zu diesem Artikel finden Sie in der Datei  <a href="200107.zip">üíæ 200107.zip</a>.</div>
	</aside>

	<section>
		<h2>Theorie des Bumpmapping</h2>
		<figure class="floatright">
			<img src="assets/200107_2.jpg" width="502" height="279" alt="DIE ZUSAMMENSETZUNG der Oberfl√§chenbeleuchtung">
			<figcaption><span>DIE ZUSAMMENSETZUNG</span> der Oberfl√§chenbeleuchtung</figcaption>
		</figure>
		<p>Der wichtige Punkt beim Bumpmapping ist: Nur die Beleuchtungs&shy;berechnung l√§sst die Unebenheiten sehen. Diese sind geometrisch nicht im Dreiecksnetz vorhanden. An den geraden Kanten eines mit Bumpmapping gerenderten 3D-Objekts sehen Sie, dass dessen Form selbst nicht ver√§ndert wird.</p>
		<p>Die Idee des Bumpmapping wurde 1978 von James Blinn entwickelt. Bumpmapping ist ein rein textur&shy;basierendes Rendering-Verfahren, um Unebenheiten auf Oberfl√§chen durch die Beleuchtung zu simulieren. Die Unebenheiten werden in einer Graustufen&shy;textur (Graustufen-Bitmap) als <i>Heightfield</i> angegeben, deren Auswirkung Sie im Bild sehen.</p>
		<p>Der Grafiker schafft nur die Graustufen-Bitmap. Daraus generiert der Programmierer Daten, wie diese f√ºr das verwendete Bumpmapping-Verfahren n√∂tig sind. Von diesen Verfahren stellen wir eines vor, dass neuere Hardware wie die GeForce GPUs von nVidia ben√∂tigt. Anschlie√üend zeigen wir Ihnen einen relativ alten Ansatz, der auf jeder 3D-Hardware funktioniert.</p>
		<figure class="floatright">
			<img src="assets/200107_4.png" width="319" height="239" alt="EINE OBERFL√ÑCHE wird durch ein Heightfield ver√§ndert.">
			<figcaption><span>EINE OBERFL√ÑCHE</span> wird durch ein Heightfield ver√§ndert.</figcaption>
		</figure>
		<p>Die Theorie der Beleuchtungs&shy;berechnung zeigt, wo das Bumpmapping ansetzt. Beleuchtung berechnen Sie aus Formeln, welche Sie mit der Vektorrechnung darstellen und verdeutlichen. Mit einer vereinfachten Formel, berechnen Sie diffuse und spiegelnde Reflexionen. Diese Formel entstammt dem Blinn-Beleuchtung&shy;smodell, das wie das Phong-Modell empirisch ermittelt wurde.</p>
		<pre><code>
C = (max(0,(L*N))
	+ max (0,(H*N))^n)
	x Dl x Dm
		</code></pre>
		<p>Blinn und Phong sind als Grundlagen&shy;forscher der Grafik&shy;programmierung ber√ºhmt. <i>Dl</i> ist die Farbe des Lichts, <i>Dm</i> die Farbe der Oberfl√§che an der betrachteten Stelle. Diese Oberfl√§chen&shy;farbe kann aus einer Textur ausgelesen sein. Der Potenzwert <i>n</i> bestimmt die Gr√∂√üe der Glanzlichter. Gr√∂√üere Werte bedeuten kleinere Glanzlichter der spiegelnden Reflexion. Die vorkommenden Vektoren bezeichnen mit<br>
		<i>‚Ä¢ L:</i> die einfallende Lichtrichtung, mit<br>
		‚Ä¢ <i>N:</i> die Normale am Oberfl√§chen&shy;punkt und mit<br>
		<i>‚Ä¢ H:</i> den so genannten Halfangle Vektor. Letzterer h√§ngt auch von der Position des Punktes auf der Oberfl√§che und der Lichtquelle ab.</p>
		<p>Wenn Sie sich obige Blinn-Formel genauer ansehen, f√§llt auf, dass es zwei Wege gibt, die Oberfl√§che nicht entsprechend der geometrischen Vorgaben, also nach dem Dreiecksnetz, darzustellen.<br>
		‚Ä¢ Der erste Ansatzpunkt: Verschieben Sie die Punkte der Oberfl√§che. Diese Technik nennt sich Displacement-Mapping und funktioniert f√ºr heutige 3D-Hardware nicht in Echtzeit.<br>
		‚Ä¢ Die zweite Variante, das Bumpmapping, setzt an der Oberfl√§chen&shy;normalen an.</p>
		<p>F√ºr ein 3D-Objekt verwenden Sie eine Textur, aus der die Farbwerte <i>Dm</i> f√ºr die Oberfl√§che gespeichert sind, und eine oder mehrere Bumpmaps, die die Perturbation (die √Ñnderung der Oberfl√§chen&shy;normalen) enth√§lt.</p>
		<p>Mit den aktuellen 3D-Grafikkarten l√§sst sich die Beleuchtung f√ºr jeden gerenderten Pixel in Echtzeit berechnen.</p>
	</section>

	<section>
		<h2>Dot Product Bumpmapping</h2>
		<p>F√ºr das Dot Product Bumpmapping Verfahren ben√∂tigen Sie moderne GPUs. Es basiert auf Bumpmaps, die als RGB-Texturen gespeichert werden. Die RGB-Werte eines Texels (zwischen 0 und 255) repr√§sentieren die <i>x-, y</i>- und <i>z</i>-Komponenten eines Vektors im Intervall <i>[-1, 1]</i>. Solche Bumpmaps k√∂nnen Sie sich aus Heightfields erzeugen lassen. Sie k√∂nnen ein Tool von nVidia (inklusive Sourcecode) downloaden, um RGB-Normal-Maps aus Heightfields zu generieren. Dieses Werkzeug finden Sie unter den Developer-Informationen auf der nVidia-Homepage zum freien Download: <a href="https://www.nvidia.com" rel="external nofollow noreferrer">www.nvidia.com</a>. Die Komponenten der Normalen&shy;vektoren werden durch Ableiten des Heightfields berechnet. Die zentrale Operation bei der Beleuchtungs&shy;berechnung des Bumpmappings und der diffusen Beleuchtung ist das Skalarprodukt aus der Normalen und des Vektors vom Oberfl√§chen&shy;punkt zur Lichtquelle:</p>
		<pre><code>N * L</code></pre>
		<p>Diese Formel entspricht dem Lambertschen Gesetz. Es ist egal, in welchem Koordinaten&shy;raum die beiden Vektoren angegeben sind, es muss aber beides mal der selbe sein. Doch welcher Raum soll das sein und in welchem ist die Normale angegeben? Die Antwort darauf gibt das Tangent Space Bumpmapping.</p>
		<p>Der entscheidende Koordinaten&shy;raum ist der so genannte Tangent Space. Diesen drei&shy;dimensionalen Raum geben Sie durch eine 3-x-3-Matrix an, deren drei Spalten&shy;vektoren den Raum aufspannen. Sie ben√∂tigen f√ºr jeden Vertex Ihres 3D-Modells einen Tangent Space. Die Normale des 3D-Modells am Vertex w√§hlen Sie als <i>+z</i>-Achse, also als dritten Spaltenvektor. Durch den Vertex und seine Normale ist eine Ebene definiert, die sich tangentiell zur Oberfl√§che befindet, daher der Name Tangent Space.</p>
		<p>Sie brauchen noch zwei weitere Vektoren, um den Raum aufzuspannen. W√§hlen Sie zum Beispiel die <i>+y</i>-Achse des Modelspace (des Koordinaten&shy;raumes, in dem Ihr 3D-Modell definiert wurde) oder einen Vektor, den Sie durch die implizite Beschreibung einer Oberfl√§che erhalten. Im Beispiel&shy;programm finden Sie daf√ºr einen Torus. Der noch fehlende dritte Vektor ergibt sich aus dem Kreuzprodukt der beiden anderen. Normalerweise werden die Vektoren so konstruiert, dass sie in der Tangential&shy;ebene an der Oberfl√§che liegen.</p>
		<p>Nun haben Sie zu jedem Vertex einen Tangent Space definiert, den Sie f√ºr das Rendern speichern m√ºssen. Die folgenden Schritte m√ºssen Sie w√§hrend der Laufzeit des Programms erledigen. Interpretieren Sie Ihr Heightfield so, dass die H√∂hen&shy;information eine Verschiebung entlang der <i>+z</i>-Achse des Tangent Space bewirkt. Sie transformieren den Vektor zur Lichtquelle in den Tangent Space: Wenn Sie Ihr 3D-Modell rendern, generieren Sie auf dem Matrix-Stack von OpenGL eine Reihe von Trans&shy;formationen. Sie ben√∂tigen die inverse Transformation. Dazu invertieren Sie entweder die resultierende <i>ModelView</i>-Matrix, oder Sie erzeugen eine Matrix mit den einzelnen invertierten Transformations&shy;schritten in umgekehrter Reihenfolge. Wenn Sie mit dieser inversen Matrix die Position der Lichtquelle in Ihrer 3D-Welt transformieren, erhalten Sie einen Ortsvektor, der die Position der Lichtquelle im Modelspace beschreibt.</p>
		<figure class="floatright">
			<img src="assets/200107_9.jpg" width="411" height="310" alt="DIE RGG-WERTE in den sechs 2D-Texturen der Cubemap repr√§sentieren normalisierte Vektoren.">
			<figcaption><span>DIE RGB-WERTE</span> in den sechs 2D-Texturen der Cubemap repr√§sentieren normalisierte Vektoren.</figcaption>
		</figure>
		<p>Als letzten Schritt berechnen Sie den Vektor eines jeden Vertex zur Lichtquelle (in Modelspace-Koordinaten) durch Subtraktion und transformieren diesen Vektor <i>L</i> in den Tangent Space. Die Transformation in den Tangent Space erfolgt durch das Skalarprodukt aus dem <i>L</i>-Vektor und jedem der Spalten&shy;vektoren.</p>
		<p>Beim Rendern eines Dreiecks durch die 3D-Hardware werden die Normalen als RGB-Tripels behandelt und linear perspektivisch korrekt interpoliert. Die <i>L</i>-Vektoren k√∂nnen sich in unter&shy;schiedlichen Tangent Spaces befinden, denn jeder Vertex des Dreiecks hat seinen eigenen Tangent Space. Die 3D-Hardware routiert gewisserma√üen die <i>L</i>-Vektoren von einem Raum in den n√§chsten.</p>
		<p>Eine mathematisch korrekte Beleuchtungs&shy;berechnung m√ºsste diese Vektoren f√ºr jeden Pixel normalisieren, da sich ihre L√§nge bei der linearen Interpolation der Vektor-Komponenten √§ndert.</p>
		<p>Daf√ºr bietet sich Cube Mapping an: Das ist eigentlich eine Form des Texture-Mapping, die einen unnormal&shy;isierten Vektor verwendet, um eine Textur zu adressieren. Diese besteht aus sechs quadratischen 2D-Bitmaps, die wie die Fl√§chen eines W√ºrfels angeordnet sind. So sehen Sie, wie ein Vektor einen Pixel adressiert.</p>
		<figure class="large">
			<img src="assets/200107_5.jpg" width="792" height="585" alt="CUBE MAPPING adressiert sechs 2D-Bitmaps mit unnormalisierten Vektoren.">
			<figcaption><span>CUBE MAPPING</span> adressiert sechs 2D-Bitmaps mit unnormalisierten Vektoren.</figcaption>
		</figure>
		<p>Die Komponente mit dem gr√∂√üten Betrag und ihr Vorzeichen bestimmen, welche Seite des W√ºrfels getroffen wird. Die 2D-Koordinaten auf der W√ºrfelseite erhalten Sie, indem Sie die beiden kleineren Komponenten durch die Gr√∂√üte dividieren. Ein RGB-Tripel, das durch die Interpolation der Normalen im Tangent Space entsteht, wird als Vektor interpretiert. Dieser Vektor schneidet den W√ºrfel an einer bestimmten Stelle. Die Lage des Schnittpunkts ist unabh√§ngig von der L√§nge des Vektors, nur die Richtung ist entscheidend.</p>
		<p>Sie k√∂nnen die Cubemap-Texturen so vorberechnen, dass an jeder Stelle ein bestimmtes RGB-Tripel gespeichert ist: das RGB-Tripel, das dem normalisierten Vektor entspricht. Im √ºbrigen werden Cubemaps dazu verwendet, Licht-Reflexionen oder -Refraktionen (Lichtbrechung) darzustellen.</p>
		<figure class="large">
			<img src="assets/200107_7.jpg" width="808" height="627" alt="UNSER DOT-3-BUMPMAPPING Programm in Aktion">
			<figcaption><span>UNSER DOT-3-BUMPMAPPING</span> Programm in Aktion</figcaption>
		</figure>
		<p>Seit 1978 haben Entwickler daran gearbeitet, das von Blinn formulierte Bumpmapping in 3D-Hardware zu integrieren. In unserem Beispiel&shy;programm finden Sie die Implementation und Fortf√ºhrung der hier gezeigten Verfahren. Mit dieser Vorarbeit k√∂nnen Sie zur Ansteuerung der GeForce-Karte √ºbergehen.</p>
	</section>

	<section>
		<h2>Register Combiners</h2>
		<p>GeForce-, Quadro- und neuere nVidia-Karten besitzen Register-Combiners. Damit l√§sst sich die Farbberechnung f√ºr jeden Pixel konfigurieren. Beachten Sie den Unterschied zwischen Konfigurieren und Programmieren: ersteres ist Einstellen, letzteres freies Gestalten. Dieses erlauben erst die Pixelshader der neuesten Karten&shy;generationen. Die Register-Combiners ersetzen, wenn Sie sie aktivieren, die Standard-OpenGL-Rendering&shy;optionen. Sie sind deutlich komplexer und flexibler. Die Register-Combiners steuern Sie √ºber OpenGL Extensions. Diese sind in der neuesten Version der Datei <i>glext.h</i> definiert, die Sie auch bei unserem Beispiel&shy;programm finden. Wie Sie die Funktionen nutzen, entnehmen Sie dem Beispiel&shy;programm. Auf den <a href="https://www.nvidia.com" rel="external nofollow noreferrer">Entwickler&shy;seiten von nVidia</a> finden Sie die genauen Spezifi&shy;kationen und Dokumen&shy;tationen aller Features.</p>
	</section>

	<section>
		<h2>Dot-3-Bumpmap-Texturen</h2>
		<figure class="floatright">
			<img src="assets/200107_6.jpg" width="723" height="339" alt="AUS EINEM HEIGHTFIELD wird eine RGB-Normalmap.">
			<figcaption><span>AUS EINEM HEIGHTFIELD</span> wird eine RGB-Normalmap.</figcaption>
		</figure>
		<p>Um eigene Bumpmaps f√ºr Dot-3-Bumpmapping zu generieren, beginnen Sie mit einem Heightfield, also einer Graustufen-Bitmap. Hellere Graustufen bedeuten, dass die so gekenn&shy;zeichnete Oberfl√§che mehr nach au√üen geschoben wird. Eine solche Bumpmap-Textur wandeln Sie mit dem nVidia-Bumpmap-Tool in eine RGB-Normal Map um:</p>
		<pre><code>normalmapgen.exe height.tga bump.tga</code></pre>
		<p>Bevor Sie die Maps in OpenGL laden, generieren Sie Mipmaps. Das sind niedrigere Aufl√∂sungs&shy;stufen einer Textur, um h√§ssliche Effekte beim Rendern zu vermeiden. In der Textur befinden sich vorzeichen&shy;behaftete Vektoren, die nur als RGB-Werte gespeichert sind. Das wei√ü die <i>gluBuild2DMipmaps(...)</i>-Funktion von OpenGL nicht, die automatisch Mipmaps generiert. Da diese f√ºr diesen Zweck unbrauchbar sind, m√ºssen Sie eigene Mipmaps generieren, also eine Funktion implementieren, die die Aufl√∂sung einer RGB-Normalmap halbiert! Dazu speichern Sie jeden Pixel der RGB-Normal in folgender Struktur, die die Vektor-Komponenten und seine L√§nge enth√§lt:</p>
		<pre><code>
typedef struct
{
	unsigned char nz, ny, nx, mag;
} DOT3NORMAL;

DOT3NORMAL bumpmap[SIZE*SIZE];
		</code></pre>
		<p><i>nx, ny</i> und <i>nz</i> initialisieren Sie jeweils mit den RGB-Werten, <i>mag</i> mit dem Wert 255. Bei der Halbierung der Aufl√∂sung fassen Sie vier benachbarte Pixel, die in einem Quadrat angeordnet sind, zu einem neuen zusammen. Die Komponenten der Vektoren <i>a,</i> <i>b, c</i> und <i>d</i> m√ºssen Sie vom Wertebereich <i>[0,255]</i> auf der Intervallskala <i>[-1,1]</i> verschieben und skalieren. Die Werte innerhalb des Intervalls multiplizieren Sie mit der L√§nge des urspr√ºnglichen Vektors und summieren sie auf. Damit erhalten Sie einen neuen Vektor, den Sie erneut normalisieren und als RGB-Tripel in der neuen Mipmap-Stufe speichern. Zus√§tzlich speichern Sie vorher seine L√§nge in <i>mag</i>. Der Code f√ºr einen Pixel sieht so aus:</p>
		<pre><code>
//a,b,c,d: Texel in bumpmap[]
// angeordnet als
// a b
// c d
DOT3NORMAL a, b, c, d;
DOT3NORMAL neu;
VERTEX n;
n.x = (a.nx / 127 - 1) * a.mag / 255;
n.x += (b.nx / 127 - 1) * b.mag / 255;
n.x += (c.nx / 127 - 1) * c.mag / 255;
n.x += (d.nx / 127 - 1) * d.mag / 255;
...

l = lengthVector(n);
normVector(n);
neu.nx = 128 + 127 * n.x;
...

neu.mag = min(255, 255 * l * 0.25);
		</code></pre>
		<p>Die so berechneten Mipmap-Stufen √ºbergeben Sie mit <i>glTexImage2D(...)</i> an OpenGL. Wenn Sie alles zusammenfassen und mit den Implementierungs&shy;details ausstatten, erhalten Sie unser fertiges Dot-3-Bumpmapping-Programm.</p>
	</section>

	<section>
		<h2>Emboss-Bumpmapping</h2>
		<figure class="floatright">
			<img src="assets/200107_3.jpg" width="276" height="370" alt="EMBOSSING bei Bumpmaps.">
			<figcaption><span>EMBOSSING</span> bei Bumpmaps.</figcaption>
		</figure>
		<p>Nun gibt es noch ein sehr altes, anderes Verfahren, um Bumpmapping darzustellen. Das Emboss-Bumpmapping ist auf jeder 3D-Karte einsetzbar. Durch diesen Fakt lie√üen sich schon manche 3D-Karten&shy;hersteller zur Behauptung verleiten, ihre 3D-Karten w√ºrden Bumpmapping in der Hardware unterst√ºtzen. Diese Methode ist mit den Embossfiltern in Bildbearbeitungs&shy;programmen verwandt. In bestimmten F√§llen sind beim Emboss-Bumpmapping Darstellungs&shy;artefakte durch Unterabtastung zu sehen, die als unscharfe Bewegungen erscheinen. Wenn Sie unser Beispiel&shy;programm dazu ausprobieren, werden Sie sehen, dass sich der Einsatz aber auf jeden Fall lohnen kann.</p>
		<p>Das Verfahren l√§sst nur die Approximation der diffusen Beleuchtungs&shy;komponente zu, womit sich die vorige Formel f√ºr die Beleuchtungs&shy;berechnung auf folgende Terme reduziert:</p>
		<pre><code>C = ((L * N)) x Dl x Dm</code></pre>
		<p>Diese Formel hat gewaltig gegen√ºber der Blinn‚Äôschen-Ausgangsformel an Komplexit√§t verloren: Es fehlen nicht nur die Rechen&shy;operationen, sondern auch der <i>Halfangle</i>-Vektor, den Sie f√ºr das Dot-3-Bumpmapping ben√∂tigten. Die Bumpmap, die wir f√ºr das Emboss-Bumpmapping einsetzen, ist eine H√∂hen&shy;information (Heightfield/Graustufen-Bitmap): Wie das erste Bild zeigte, repr√§sentiert ein Pixel in der Bumpmap eine H√∂hen&shy;verschiebung auf der Oberfl√§che.</p>
		<figure class="large">
			<img src="assets/200107_8.jpg" width="808" height="627" alt="UNSER BEISPIELPROGRAMM f√ºr Emboss-Bumpmapping">
			<figcaption><span>UNSER BEISPIELPROGRAMM</span> f√ºr Emboss-Bumpmapping</figcaption>
		</figure>
		<p>Wir betrachten das Verfahren zun√§chst im Ein&shy;dimensionalen, also mit einer Zahlenreihe, die einen H√∂henverlauf darstellt. Wenn Ihnen die erste Ableitung einer Folge von H√∂henwerten vorliegt, entspricht diese der Steigung am entsprechenden Oberfl√§chen&shy;punkt. Diese Steigung <i>m</i> wird verwendet, um einen Basisfaktor <i>Fd</i> f√ºr die diffuse Beleuchtung zu erh√∂hen oder zu erniedrigen. Die Summe <i>(Fd+m)</i> approximiert den Term <i>(L*N)</i>.</p>
		<p>Als n√§chstes approximieren Sie die Steigung. Lesen Sie die H√∂he <i>H0</i> des Oberfl√§chen&shy;punktes aus der entsprechende Stelle der Heightmap, was sp√§ter die 3D-Hardware f√ºr Sie erledigen wird. Lesen Sie die H√∂he erneut aus, wobei Sie die Bumpmap ein kleines St√ºckchen in Richtung der Lichtquelle verschieben, und Sie erhalten <i>H1</i>. Rechnen Sie diese Verschiebung aus. Die Differenz aus <i>H0</i> und <i>H1</i> ergibt: <i>m = H1 - H0.</i></p>
		<p>Die Textur verschieben Sie, indem Sie die Textur&shy;koordinaten modifizieren. Die Modifikation berechnen Sie wieder im Tangent Space. Dazu transformieren Sie die Lichtquelle in den Modelspace. Bilden Sie die Skalarprodukte des Vektors von einem Vertex zur Lichtquelle und der Tangente sowie der Binormalen des Tangent Space. Damit erhalten Sie zwei Verschiebung&shy;swerte, die Sie zur urspr√ºnglichen Texture-Koordinaten addieren.</p>
		<p>Wenn Sie die Texturen und Bumpmaps in OpenGL geladen haben, f√ºhren Sie das Emboss-Bumpmapping in drei Renderpasses durch. Diese Variante funktioniert auf jeder OpenGL-Hardware, die Texture-Mapping unterst√ºtzt.<br>
		‚Ä¢ Im ersten Renderpass verwenden Sie die Bumpmap-Textur mit den Original-Textur&shy;koordinaten und deaktivieren die OpenGL-Beleuchtungs&shy;berechnung und das Blending.</p>
		<pre><code>
glBindTexture(GL_TEXTURE_2D, bumpTex);
glDisable(GL_BLEND);
glDisable(GL_LIGHTING);
renderObject();
		</code></pre>
		<p>‚Ä¢ Im zweiten Schritt erhalten Sie die 3D-Objekte mit fertiger Beleuchtung, jedoch ohne Farbe. Dazu w√§hlen Sie die invertierte Bumpmap-Texture, Blending mit <i>GL_ONE/GL_ ONE</i> und den berechneten verschobenen Textur&shy;koordinaten:</p>
		<pre><code>
glBindTexture(GL_TEXTURE_2D, invBumpTex);
glBlendFunc(GL_ONE, GL_ONE);
glDepthFunc(GL_LEQUAL);
glEnable(GL_BLEND);
renderObjectEmboss();
		</code></pre>
		<p>‚Ä¢ Im dritten Renderpass kommt Farbe durch die Farbtextur und die OpenGL-Beleuchtung ins Spiel. Dazu verwenden Sie folgende Einstellungen:</p>
		<pre><code>
glBindTexture(GL_TEXTURE_2D, textureMap);
glBlendFunc(GL_DST_COLOR, GL_SRC_COLOR);
glEnable(GL_LIGHTING);
renderObject();
		</code></pre>
		<p>Probieren Sie die High-End-Render&shy;techniken aus. Wenn Sie Ihre 3D-Grafik mit den Bumpmapping-Features ausstatten, werden Sie feststellen, wie realistisch bisher flache, k√ºnstlich anmutende 3D-Objekte auf den Betrachter wirken k√∂nnen.</p>
		<p>Um die mathematische Arbeit von James Blinn zu studieren, verweisen wir auf die nachfolgenden Literatur&shy;angaben. Diese Grundlagen f√ºr die Berechnung von 3D-R√§umen wurden erst in den letzten Jahren gelegt. Die komplexe mathematische Materie ist noch nicht vollst√§ndig erforscht.</p>
	</section>

	<footer>
		<p>Erhard Thomas</p>
		<p>¬© 2001 WEKA Computerzeitschriften Verlag</p>
		<p class="footnote"><b>Literatur:</b></p>
		<p class="footnote">Mark J. Kilgard;, A Practical and Robust Bump-mapping Technique for Today‚Äôs GPUs, Developer Information: www.nvidia.com</p>
		<p class="footnote">James Blinn, Simulation of Wrinkled Surfaces, Computer Graphics (Proc. Siggraph ‚Äò78), August 1978, Seite 286ff</p>
		<p class="footnote">Tomas M√∂ller, Eric Haines, Real-Time Rendering, AK Peters Ltd, ISBN 1-56-881-101-2, 102 Mark, 482 Seiten, 1999</p>
	</footer>
	</article>

	<nav class="pagenav">
		<a rel="prev" href="200106.html">6/2001</a>
		<a href="index.html">Inhalt</a>
		<a rel="next" href="200108.html">8/2001</a>
	</nav>
</body>
