<!DOCTYPE html>
<html lang="de">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="style.css">
	<title>Schattenspiel (PC Underground, PC Magazin 8/2004)</title>
</head>
<body>
	<div class="credits">
		<h2>Dieser Artikel erschien erstmals im PC&nbsp;Magazin&nbsp;8/2004. Die Wieder&shy;ver√∂ffentlichung erfolgt mit freundlicher Genehmigung der <a rel="external nofollow noreferrer" href="https://www.weka-media-publishing.de">WEKA&nbsp;Media&nbsp;Publishing&nbsp;GmbH</a>.</h2>
	</div>

	<nav class="pagenav">
		<a rel="prev" href="200406.html">6/2004</a>
		<a href="index.html">Inhalt</a>
		<a rel="next" href="200409.html">9/2004</a>
	</nav>

	<article>
	<header>
		<h2>Deferred Shading ‚Äì Beleuchtung als Post Processing</h2>
		<h1>Schatten<span class="highlight">spiel</span></h1>
		<p class="summary">Mit <i>Deferred-shading-</i>Techniken zeichnen Sie Ihre 3D-Szenen zun√§chst v√∂llig ohne Beleuchtungs&shy;berechnung. Diese √ºbernimmt einmalig ein <span class="highlight">finaler Nachbear&shy;beitungsschritt</span> f√ºr jeden sichtbaren Pixel.</p>
	</header>

	<section>
		<h3>Carsten Dachsbacher</h3>
		<figure class="floatright">
			<img src="assets/200408_1.jpg" width="504" height="470" alt="Deferred Shading: Sie berechnen die Beleuchtung nur einmal pro Pixel.">
			<figcaption><span>Deferred Shading:</span> Sie berechnen die Beleuchtung nur einmal pro Pixel.</figcaption>
		</figure>
		<p>Das <i>Deferred Shading</i> konstruiert die Geometrie einer 3D-Szene zun√§chst ohne Beleuchtungs&shy;berechnung. Dabei zeichnen Sie nicht in den normalen sichtbaren Framebuffer, sondern in so genannte Fat-Buffers.</p>
		<p>Der Name kommt daher, dass diese Buffer, verteilt auf mehrere gleichzeitig beschreibbare Rendertargets, verh√§ltnis&shy;m√§√üig viel Daten pro Pixel enthalten, wie z.B. die 3D-Position und die Normale der ‚Äì in diesem Pixel ‚Äì sichtbaren Oberfl√§che. Nach dem Zeichnen der Szene wird die Beleuchtungs&shy;berechnung f√ºr jeden Pixel durchgef√ºhrt: die daf√ºr notwendige Information befindet sich in den Fat-Buffers. F√ºr diese Technik ben√∂tigen Sie nat√ºrlich modernere, programmier&shy;bare Grafikkarten der DirectX9-Generation, um zum Einen die Rendertargets (dynamische Texturen) zu beschreiben und zum Anderen die Beleuchtungs&shy;berechnung in einem Pixel-Shader zu programmieren.</p>
	</section>

	<aside>
		<h2>QUELLTEXTE</h2>
		<div>Die Quelltexte zu diesem Artikel finden Sie in der Datei  <a href="200408.zip">üíæ 200408.zip</a>.</div>
	</aside>

	<section>
		<h2>Vergleich</h2>
		<p>Unter den vielen Varianten Lighting/Shading f√ºr das Echtzeit-Rendering, greifen wir an dieser Stelle drei Varianten heraus, die mit dynamischen Lichtquellen und lokaler Beleuchtungs&shy;berechnung arbeiten. Das Single-Pass-Verfahren berechnet das Lighting direkt beim Rendern der Geometrie. Dieser Ansatz ist gut geeignet, um Szenen mit wenigen Lichtquellen darzustellen. Bei einer gro√üen Anzahl von Lichtquellen wird die Organisation der Shader und der Lichtquellen, die f√ºr ein Objekt relevant sind, schwierig und der Vertex/Pixel Shader leicht zu komplex. Beim Multi Pass Lighting wird jeweils nur eine Lichtquelle auf ein Objekt angewendet und dieses gegebenenfalls mehrfach gezeichnet und in den Framebuffer geblendet. Das Problem hierbei ist der entstehende Aufwand bei der Verwaltung und dem Rendering von Lichtquellen und Objekten.</p>
		<p>Beim Deferred Shading m√ºssen Sie sich um die Zahl der endg√ºltig angewendeten Lichtquellen beim Zeichnen der Objekte keine Gedanken machen. F√ºr die Performance ist es auch nahezu egal, ob Sie viele klein- oder wenige gro√üfl√§chige Lichtquellen in Ihrer Szene verwenden.</p>
	</section>

	<section>
		<h2>Multiple Render Targets</h2>
		<p>In den Rendertargets, also dem Ergebnis des Geometrie-Renderings, ben√∂tigen Sie neben der 3D-Position jedes Pixels und seiner Normale noch Material&shy;parameter. Diese k√∂nnen je nach verwendetem Beleuchtungs&shy;modell variieren. Typischerweise umfassen die Parameter die diffuse Oberfl√§chen&shy;farbe, spekulare Reflektion und eventuell auch Parameter f√ºr Lichtemission und Subsurface-Scattering.</p>
		<p>Prinzipiell sollten Sie die Datenmenge aber so gering wie m√∂glich halten, wie das folgende Beispiel zeigt. Nehmen Sie an, Sie speichern die Position in einem <i>A32R32G32B32</i> Rendertarget (32 Bit IEEE Float f√ºr alle vier Komponenten), die Normale, diffuse Farbe und zus√§tzliche Material&shy;parameter jeweils als <i>A8R8G8B8</i>-Rendertarget. Somit w√ºrden Sie pro Pixel bereits 224 Bits speichern, was sich bei einer Aufl√∂sung von 1024x768 auf 21 Megabyte summieren w√ºrde, ohne das Sie Anti-Aliasing verwenden k√∂nnten. Ein dabei verschwiegenes Problem ist, dass die momentane Grafikhardware es gar nicht erlaubt, unterschied&shy;liche Bit-Tiefen bei multiplen Rendertargets zu verwenden.</p>
		<p>In unserem Beispiel&shy;programm verwenden Sie die folgende Konfiguration, wobei wir uns auf 32-Bit-Rendertargets beschr√§nken wollen. Um trotzdem eine gen√ºgend hohe Genauigkeit zu erzielen, teilen Sie die 3D-Position auf zwei Rendertargets mit je zwei 16-Bit-Float-Werten auf (D3DFMT_G16R16F). Die Normale speichern Sie entweder in einem <i>A8R8G8B8</i> Target, d.h. mit drei 8-Bit-Komponenten und einem noch unbelegten Byte f√ºr weitere Daten oder, wenn Sie noch mehr Genauigkeit w√ºnschen, in einem <i>A2R10G10B10</i> Rendertarget, also mit 10 Bit pro Komponente. Die Material&shy;parameter beschr√§nken sich in unserem Beispiel auf eine diffuse Farbe, die Sie in ein <i>A8R8G8B8</i> Target schreiben.</p>
	</section>

	<section>
		<h2>Implementation</h2>
		<p>Unser Beispiel&shy;programm verwendet Direct3D9 und basiert auf dem Framework, das Sie vielleicht schon aus fr√ºheren Ausgaben kennen. Den vollst√§ndigen Quelltext finden Sie wie immer auf der Heft CD. Die Beschreibung hier konzentriert sich deshalb auf die relevanten Teile f√ºr die Deferred Shading Konzepte.</p>
		<p>Die Rendertargets legen Sie mit der <i>D3DXCreateTexture</i>-Methode an. Wichtig ist, dass Sie bei dem Verwendungszweck der Textur (Usage-Flag) <i>D3DUSAGE_RENDERTARGET</i> angeben und das entsprechende Pixelformat w√§hlen. Mit der <i>GetSurfaceLevel</i> Methode des <i>IDIRECT3DTEXTURE9</i>-Interfaces (also Ihres Textur-Objektes) holen Sie sich einen Zeiger auf die erste Surface Ihrer Rendertarget-Textur.</p>
		<p>In dem initialen Renderpass beschreiben Sie also die Rendertargets, deren Verwendung Sie Direct3D zun√§chst mitteilen m√ºssen. Vorher holen Sie die Referenz auf den Backbuffer ein, auf den das sp√§ter sichtbare Bild gerendert wird:</p>
		<pre><code>
LPDIRECT3DSURFACE9 lpBackBuffer;
		</code></pre>
		<p>Anschlie√üend k√∂nnen Sie schon beginnen, die Geometrie zu rendern. Um die multiplen Rendertargets beschreiben zu k√∂nnen, ben√∂tigen Sie einen Vertex und Pixel Shader, den das Beispiel&shy;programm mit der Microsoft High Level Shader Language und einem Effect File definiert:</p>
		<pre><code>
pEffect-&gt;SetTechnique("InitialPass");
renderScene();
		</code></pre>
		<p>Der Vertex Shader √ºbernimmt dabei die herk√∂mmliche Transformation der Vertices f√ºr die Rasterisierung (matMVP Matrix) und die Transformation der Koordinaten in den World Space (matMV), um sp√§ter die Beleuchtung zu berechnen. Diese werden ‚Äì genauso, wie die Normale und die Textur-Koordinaten (f√ºr normales Textur-Mapping) ‚Äì in den Textur-Koordinaten-Registern an die Rasterisierungs&shy;einheit √ºbergeben:</p>
		<pre><code>
FRAGMENT vsInitialPass(VERTEX vertex)
...
return f;
}
		</code></pre>
		<figure class="floatright">
			<img src="assets/200408_2.jpg" width="504" height="470" alt="World Space: Der genaue Ort der Oberfl√§che liegt im Raum.">
			<figcaption><span>World Space:</span> Der genaue Ort der Oberfl√§che liegt im Raum.</figcaption>
		</figure>
		<figure class="floatright">
			<img src="assets/200408_3.jpg" width="504" height="470" alt="Die Normale: Sie ist wichtig f√ºr die Beleuchtungs&shy;berechnung.">
			<figcaption><span>Die Normale:</span> Sie ist wichtig f√ºr die Beleuchtungs&shy;berechnung.</figcaption>
		</figure>
		<p>Der Pixel Shader nimmt diese Informationen, vom Rasterisierer f√ºr jeden Pixel interpoliert, entgegen, erledigt das normale Textur-Mapping und kodiert und verteilt die Information auf die Rendertargets.</p>
		<pre><code>
struct FRAGRESULT
{
	float4 color[4] : COLOR;
};

FRAGRESULT psInitialPass(FRAGMENT fragment)
{
	FRAGRESULT f;
		</code></pre>
		<p>Mit diesen Shadern rendern Sie Ihre komplette Geometrie. F√ºr den zweiten und letzten Renderpass setzen Sie als Rendertarget wieder den urspr√ºnglichen Backbuffer:</p>
		<pre><code>
pD3DDevice-&gt;SetRenderTarget(1, NULL);
pD3DDevice-&gt;SetRenderTarget(2, NULL);
pD3DDevice-&gt;SetRenderTarget(3, NULL);
pD3DDevice>SetRenderTarget(0, lpBackBuffer);
		</code></pre>
		<p>Als Beispiel beleuchten Sie jetzt die Szene mit einer Lichtquelle. Dazu rendern Sie ein bildschirm&shy;f√ºllendes Rechteck, auf das die Rendertargets als Textur gespannt sind. Dazu verwenden Sie folgenden Code, wobei die Abbildungs&shy;matrizen die Identit√§ts&shy;abbildung enthalten:</p>
		<pre><code>
typedef struct
{
	float x, y, z, u, v;
} TEXTUREDVERTEX;

TEXTUREDVERTEX screenQuad[] = {
	{ -1, -1, 0, 0, 1 },
	{ -1,  1, 0, 0, 0 },
	{  1, -1, 0, 1, 1 },
	{  1,  1, 0, 1, 0 },
};

pD3DDevice-&gt;SetFVF(D3DFVF_XYZ|D3DFVF_TEX1);
pD3DDevice-&gt;SetRenderState(D3DRS_CULLMODE, D3DCULL_CCW);
pD3DDevice-&gt;DrawPrimitiveUP(D3DPT_TRIANGLESTRIP,
	2, screenQuad, sizeof(TEXTUREDVERTEX));
		</code></pre>
		<p>	Die Beleuchtungs&shy;berechnung √ºbernimmt der folgende Pixel Shader, der ebenfalls im <i>Effect</i>-File definiert ist.</p>
		<pre><code>
struct FRAGMENT_DEFERRED
		</code></pre>
		<p>Zun√§chst lesen Sie die vier ehemaligen Rendertargets aus:</p>
		<pre><code>
float4 posXY, posZ, normal, color;
		</code></pre>
		<p>Und rekonstruieren die Normale bzw. World Space Position:</p>
		<pre><code>
normal = normalize(normal * 2.0 - 1.0);
float4 worldSpacePos =
	float4(posXY.x, posXY.y, posZ.x, 1.0);
		</code></pre>
		<p>Anschlie√üend f√ºhren Sie die Beleuchtungs&shy;berechnung aus und modulieren die diffuse Oberfl√§chen&shy;farbe und addieren die spekulare Beleuchtung. So erhalten Sie den endg√ºltigen Farbwert, den Sie in den Framebuffer schreiben:</p>
		<pre><code>
float4 eye, light, reflection, lit;
		</code></pre>
	</section>

	<section>
		<h2>Mehr Licht</h2>
		<p>Wenn Sie die Szene mit weiteren Lichtquellen beleuchten wollen, m√ºssen Sie den letzten Renderpass einfach nur wiederholen und dabei additives Blending im Framebuffer einstellen. Bei lokalen Lichtquellen, die nur einen Teil der Szene ausleuchten sollen, wie z.B. durch eine entfernungs&shy;abh√§ngige Abschw√§chung, m√ºssen Sie nicht jedes Mal den ganzen Bildschirm f√ºllen. Stattdessen sparen Sie Rendering-Zeit, indem Sie nur den Teil des Bildschirms erneut rendern, der im Einflussgebiet der Lichtquelle liegt. Dazu erzeugen Sie f√ºr jede dieser Lichtquellen ‚Äì als Vorberechnungs&shy;schritt ‚Äì ein einfaches konvexes Dreiecksnetz, das den ausge&shy;leuchteten Raum enth√§lt. Dieses Dreiecksnetz rendern Sie mit dem entsprechenden Pixel Shader f√ºr die Beleuchtung. Der von diesem Netz bedeckte Bereich am Bildschirm ist der, den die Lichtquelle potentiell beeinflusst und f√ºr den Sie die Beleuchtungs&shy;berechnung durchf√ºhren m√ºssen. Wichtig ist dabei, dass jeder Pixel nur einmalig behandelt wird. Bei konvexen Dreiecksnetzen k√∂nnen Sie das durch Backface Culling erwirken. Achten Sie dabei darauf, dass Sie nur die Vorderseiten rendern, wenn sich die Kamera au√üerhalb des Netzes befindet, ansonsten rendern Sie die R√ºckseiten.</p>
		<p>Ein weiteres Problem ergibt sich, wenn das Netz die Near und/oder <i>Far Clipplane</i> schneidet. Diese F√§lle m√ºssen Sie speziell, z.B. durch <i>Clamping</i> des Volumens im Vertex Shader, behandeln. Um das Rendering zu beschleunigen, k√∂nnen Sie f√ºr das Zeichnen dieser Light Volumes Z-Buffering verwenden. Die notwendige Information haben Sie durch das Rendern im initialen Pass schon im Tiefenpuffer gespeichert. Je nachdem, ob Sie Vorder- oder R√ºckseiten zeichnen, verwenden Sie als Z-Buffer Test <i>D3DCMP_LESS</i> bzw. <i>D3DCMP_GREATER</i>.</p>
	</section>

	<section>
		<h2>Frame Buffer Optimierungen</h2>
		<p>Der hohe Speicherbedarf der Rendertargets kann dazu f√ºhren, dass die Grafikhardware durch viel Speicher&shy;transfer ausgebremst wird. Um dies zu vermeiden, k√∂nnen Sie die Menge der gespeicherten Information reduzieren, wenn Sie daf√ºr etwas mehr Rechenaufwand in Kauf nehmen. Die Frage, welche der im folgenden vorgestellten Optionen am schnellsten ist, h√§ngt vom jeweiligen Einsatz, Beleuchtungs&shy;modell und Grafikkarte ab und l√§sst sich im Vornherein nicht beantworten.</p>
		<p>Den gr√∂√üten Teil der Daten nimmt das Speichern der World Space Position ein. Dabei ist durch die 2D-Position eines Pixels auf dem Bildschirm und die Kamera&shy;parameter ein Sichtstrahl durch jeden Pixel im Raum definiert. Statt der World Space Position speichern Sie die Entfernung zum ersten Oberfl√§chen&shy;punkt, den der Strahl schneidet. Dadurch k√∂nnen Sie die Position im Beleuchtungs-Renderpass berechnen. Diese Entfernung ist dabei nichts anderes als der Tiefenpuffer. Leider k√∂nnen Sie nicht performant auf den Tiefenpuffer der Grafikkarte zugreifen, aber Sie k√∂nnen die Information selbst berechnen und in einem Rendertarget speichern. Wenn Sie daf√ºr einen 32-Bit-IEEE-Float verwenden, haben Sie die Information schon deutlich reduziert: In unserem Beispiel&shy;programm w√ºrden Sie ein Rendertarget bzw. 32 Bit pro Pixel sparen.</p>
		<p>Die Normale k√∂nnen Sie auch etwas sparsamer kodieren. Bei einer normalisierten Normale ist <i>x<sup>2</sup> + y<sup>2</sup> + z<sup>2</sup> = 1</i>. Wenn Sie nur zwei Komponenten speichern wie <i>x</i> und <i>y</i> k√∂nnen Sie die dritte im Pixel Shader berechnen: <i>z = sqrt(1 - x<sup>2</sup> - y<sup>2</sup>)</i>. Eine dritte Option ist, dass Sie die Material&shy;parameter nicht direkt in den Fat-Buffers speichern, sondern nur einen Index bzw. Verweis. Dieser Index wird im Beleuchtungs-Renderpass dazu verwendet, um die tats√§chlichen Material&shy;parameter aus einer Textur auszulesen.</p>
	</section>

	<section>
		<h2>High Dynamic Range (HDR)</h2>
		<figure class="large">
			<img src="assets/200408_5.jpg" width="504" height="470" alt="High Dynamic Range: Sie zeigt eine diffuse Beleuchtung und sehr helle spekulare Reflektion.">
			<figcaption><span>High Dynamic Range:</span> Sie zeigt eine diffuse Beleuchtung und sehr helle spekulare Reflektion.</figcaption>
		</figure>
		<figure class="floatright">
			<img src="assets/200408_4.png" width="504" height="470" alt="Glow: Die spekulare Beleuchtung wird dank HDR √ºbersteuert.">
			<figcaption><span>Glow:</span> Die spekulare Beleuchtung wird dank HDR √ºbersteuert.</figcaption>
		</figure>
		<p>Wenn Sie die Renderpasses f√ºr die Beleuchtung nicht direkt in den Framebuffer ausf√ºhren, sondern in weitere Rendertargets mit Floating-Point-Genauigkeit, k√∂nnen Sie den Wertebereich der erfassbaren Licht&shy;intensit√§t erh√∂hen. Allerdings m√ºssen Sie sich um das additive Blending selbst bem√ºhen. Das Rendering mit erh√∂htem Wertebereich wird mit High Dynamic Range Rendering bezeichnet. Diese Information gilt es nat√ºrlich auf den normalen Helligkeits&shy;bereich des Monitors bzw. Framebuffers abzubilden. Allerdings lassen sich Helligkeits&shy;szenarien programmieren. Zudem k√∂nnen Sie Post-Processing-Effekte wie Glow anwenden.</p>
	</section>

	<section>
		<h2>Vor- und Nachteile</h2>
		<p>Die Vorteile von Deferred Shading ist die einfache Handhabung von sehr komplexen Szenen mit vielen Lichtquellen, komplexen Objekten und Post-Processing Effekten. Au√üerdem zeichnen Sie jedes Objekt nur einmalig und schattieren auch jeden Pixel nur einmal. Der Nachteil liegt im nicht vern√ºnftig machbaren Alpha Blending, der hohen Speicher&shy;bandbreite und darin, dass Sie Hardware Multisampling nicht verwenden k√∂nnen. Und nicht zu vergessen: Sie ben√∂tigen Hardware, die Pixel-Shader unterst√ºtzt, denn alle Beleuchtungs&shy;berechnungen sind darauf angewiesen.</p>
	</section>

	<footer>
		<p>Erhard Thomas</p>
		<p>¬© 2004 WEKA Computerzeitschriften Verlag</p>
		<p class="footnote"><a href="https://www.dachsbacher.de/pcu" rel="external nofollow noreferrer">www.dachsbacher.de/pcu</a></p>
		<p class="footnote"><a href="https://www.ati.com/developer/" rel="external nofollow noreferrer">www.ati.com/developer/</a></p>
	</footer>
	</article>

	<nav class="pagenav">
		<a rel="prev" href="200406.html">6/2004</a>
		<a href="index.html">Inhalt</a>
		<a rel="next" href="200409.html">9/2004</a>
	</nav>
</body>
